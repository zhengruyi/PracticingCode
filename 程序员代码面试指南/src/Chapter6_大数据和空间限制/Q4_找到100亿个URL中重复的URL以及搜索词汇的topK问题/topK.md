###找到重复的URL
有一个包含100亿个URL的大文件，假设每个URL站占用64B，请找出所有重复的URL

1.把100亿字节的文件通过哈希函数，分配到多台机器上，或者分割成多个小文件
然后对每个小文件来统计是否有重复的URL

结论：很多大数据问题都离不开分流，要么是哈希函数把大文件的内容分配给
不同的机器，要么是哈希函数把大文件分成小文件，然后处理每一个小数量的集合


###找到最热的TopK问题
某搜索公司一天的搜索词汇是海量的（百亿数据量），请设计一种求出每天最热
Top100词汇的额可行性办法

1.把百亿数据量的词汇文件分流到不同的机器上，机器数量由限制条件
来计算，对于每一台机器来说如果数据量任然超过内存，则可以继续分割成小文件

2.处理每一个小文件时，哈希表统计每种词以及词频，哈希表记录建立完成后
，遍历哈希表得到前100词汇和对应的词频。对所有小文件的前100词汇采用大顶堆
排序得到整个大文件的前100热门词汇

3.对所有的大文件都采用相同操作，然后采用大顶堆对所有大文件的前100词汇
进行排序，得到整体的Top100词汇